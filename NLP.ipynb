{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e35bf3c-afa5-410c-9bcb-e4149d68641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The primary goal of Natural Language Processing (NLP) is to enable computers to understand, interpret, generate, and respond to human language in a way that is both meaningful and useful. It bridges the gap between human communication (natural language) and computer systems, making it possible for machines to process and analyze large volumes of text or speech.\\n\\nKey objectives include:\\n\\nLanguage Understanding: Enabling computers to comprehend the meaning and context of written or spoken language.\\nLanguage Generation: Producing human-like text or speech based on data and input.\\nInformation Extraction: Deriving structured information (e.g., entities, relationships) from unstructured text.\\nSentiment Analysis: Understanding emotions, opinions, or sentiments expressed in text.\\nText Summarization: Condensing large pieces of text into shorter summaries.\\nMachine Translation: Translating text or speech from one language to another.\\nSpeech Recognition: Converting spoken language into text.\\nQuestion Answering: Providing precise answers to user queries.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1).What is the primary goal of Natural Language Processing (NLP)?\n",
    "'''The primary goal of Natural Language Processing (NLP) is to enable computers to understand, interpret, generate, and respond to human language in a way that is both meaningful and useful. It bridges the gap between human communication (natural language) and computer systems, making it possible for machines to process and analyze large volumes of text or speech.\n",
    "\n",
    "Key objectives include:\n",
    "\n",
    "Language Understanding: Enabling computers to comprehend the meaning and context of written or spoken language.\n",
    "Language Generation: Producing human-like text or speech based on data and input.\n",
    "Information Extraction: Deriving structured information (e.g., entities, relationships) from unstructured text.\n",
    "Sentiment Analysis: Understanding emotions, opinions, or sentiments expressed in text.\n",
    "Text Summarization: Condensing large pieces of text into shorter summaries.\n",
    "Machine Translation: Translating text or speech from one language to another.\n",
    "Speech Recognition: Converting spoken language into text.\n",
    "Question Answering: Providing precise answers to user queries.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c144ffd8-c6f7-4e88-9b9e-8513b4d42286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2)What does \"tokenization\" refer to in text processing?\\nTokenization is the process of breaking a text into smaller units called tokens, which can be words, phrases, or sentences. These tokens are the building blocks for text analysis and are used to prepare the text for further processing, such as lemmatization or part-of-speech tagging.\\nExample:\\nText: \"Natural Language Processing is exciting.\"\\nWord Tokenization: [\"Natural\", \"Language\", \"Processing\", \"is\", \"exciting\"]\\nSentence Tokenization: [\"Natural Language Processing is exciting.\"]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''2)What does \"tokenization\" refer to in text processing?\n",
    "Tokenization is the process of breaking a text into smaller units called tokens, which can be words, phrases, or sentences. These tokens are the building blocks for text analysis and are used to prepare the text for further processing, such as lemmatization or part-of-speech tagging.\n",
    "Example:\n",
    "Text: \"Natural Language Processing is exciting.\"\n",
    "Word Tokenization: [\"Natural\", \"Language\", \"Processing\", \"is\", \"exciting\"]\n",
    "Sentence Tokenization: [\"Natural Language Processing is exciting.\"]'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08db7448-4912-4fe9-addb-2c033681c701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3)What is the difference between lemmatization and stemming?\\n\\nLemmatization: Reduces words to their base or dictionary form (lemma) while considering the word\\'s context and grammar.\\nExample: \"running\" → \"run\" (verb), \"better\" → \"good\".\\nStemming: Reduces words to their root form by chopping off suffixes or prefixes without considering the word\\'s context.\\nExample: \"running\" → \"run\", \"studies\" → \"studi\".\\nLemmatization is more accurate but computationally intensive compared to stemming.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''3)What is the difference between lemmatization and stemming?\n",
    "\n",
    "Lemmatization: Reduces words to their base or dictionary form (lemma) while considering the word's context and grammar.\n",
    "Example: \"running\" → \"run\" (verb), \"better\" → \"good\".\n",
    "Stemming: Reduces words to their root form by chopping off suffixes or prefixes without considering the word's context.\n",
    "Example: \"running\" → \"run\", \"studies\" → \"studi\".\n",
    "Lemmatization is more accurate but computationally intensive compared to stemming.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd290220-45fe-4209-a7fe-14068a649502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6052\\130480477.py:1: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  '''4)What is the role of regular expressions (regex) in text processing?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4)What is the role of regular expressions (regex) in text processing?\\nRegular expressions (regex) are patterns used for searching, matching, and manipulating text. In text processing, regex is useful for tasks like:\\nIdentifying patterns (e.g., email addresses, dates, phone numbers).\\nRemoving unwanted characters (e.g., punctuation, HTML tags).\\nExtracting specific text fragments.\\nExample: Extracting email addresses: \\x08[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Z|a-z]{2,}\\x08.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''4)What is the role of regular expressions (regex) in text processing?\n",
    "Regular expressions (regex) are patterns used for searching, matching, and manipulating text. In text processing, regex is useful for tasks like:\n",
    "Identifying patterns (e.g., email addresses, dates, phone numbers).\n",
    "Removing unwanted characters (e.g., punctuation, HTML tags).\n",
    "Extracting specific text fragments.\n",
    "Example: Extracting email addresses: \\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbf2a7c-08c5-46ee-84b3-bcae99db6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5)What is Word2Vec and how does it represent words in a vector space?\\nWord2Vec is a neural network-based algorithm that represents words as dense vectors in a continuous vector space, capturing semantic relationships. It uses two architectures:\\nSkip-gram: Predicts surrounding words given a target word.\\nCBOW (Continuous Bag of Words): Predicts a target word based on its surrounding context.\\nThe resulting vectors place semantically similar words closer in the vector space.\\nExample: The words \"king\" and \"queen\" will have similar vectors, and vector arithmetic can capture analogies like:\\nvector(\"king\") - vector(\"man\") + vector(\"woman\") ≈ vector(\"queen\").'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''5)What is Word2Vec and how does it represent words in a vector space?\n",
    "Word2Vec is a neural network-based algorithm that represents words as dense vectors in a continuous vector space, capturing semantic relationships. It uses two architectures:\n",
    "Skip-gram: Predicts surrounding words given a target word.\n",
    "CBOW (Continuous Bag of Words): Predicts a target word based on its surrounding context.\n",
    "The resulting vectors place semantically similar words closer in the vector space.\n",
    "Example: The words \"king\" and \"queen\" will have similar vectors, and vector arithmetic can capture analogies like:\n",
    "vector(\"king\") - vector(\"man\") + vector(\"woman\") ≈ vector(\"queen\").'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565373cf-03b7-44ce-9440-f2d70ac9c5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6)How does frequency distribution help in text analysis?\\nFrequency distribution shows how often each word or token appears in a text. This helps:\\n\\nIdentify common terms and stopwords.\\nUnderstand the overall theme of a document.\\nPerform feature engineering for NLP models.\\nExample: In a news article, frequent words like \"economy\", \"growth\", and \"market\" might indicate the article is about financial trends.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''6)How does frequency distribution help in text analysis?\n",
    "Frequency distribution shows how often each word or token appears in a text. This helps:\n",
    "\n",
    "Identify common terms and stopwords.\n",
    "Understand the overall theme of a document.\n",
    "Perform feature engineering for NLP models.\n",
    "Example: In a news article, frequent words like \"economy\", \"growth\", and \"market\" might indicate the article is about financial trends.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21013727-bc29-4f82-ad50-120bfc3a2e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7)Why is text normalization important in NLP?\\nText normalization ensures consistency in text data by converting it into a standard form. This helps reduce noise and improves the performance of NLP models. Common normalization steps include:\\n\\nLowercasing: Converts all text to lowercase.\\nRemoving punctuation and stopwords.\\nExpanding contractions (e.g., \"don\\'t\" → \"do not\").\\nConverting numbers into words (e.g., \"3\" → \"three\").'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''7)Why is text normalization important in NLP?\n",
    "Text normalization ensures consistency in text data by converting it into a standard form. This helps reduce noise and improves the performance of NLP models. Common normalization steps include:\n",
    "\n",
    "Lowercasing: Converts all text to lowercase.\n",
    "Removing punctuation and stopwords.\n",
    "Expanding contractions (e.g., \"don't\" → \"do not\").\n",
    "Converting numbers into words (e.g., \"3\" → \"three\").'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf4b065-1da1-4fe4-a45e-6e2236125960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8)What is the difference between sentence tokenization and word tokenization?\\n\\nSentence Tokenization: Splits text into sentences. Useful for tasks like summarization and sentiment analysis at the sentence level.\\nExample: \"I love NLP. It is fascinating.\" → [\"I love NLP.\", \"It is fascinating.\"]\\nWord Tokenization: Splits sentences into individual words. Used for tasks like word frequency analysis and text classification.\\nExample: \"I love NLP.\" → [\"I\", \"love\", \"NLP\", \".\"]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''8)What is the difference between sentence tokenization and word tokenization?\n",
    "\n",
    "Sentence Tokenization: Splits text into sentences. Useful for tasks like summarization and sentiment analysis at the sentence level.\n",
    "Example: \"I love NLP. It is fascinating.\" → [\"I love NLP.\", \"It is fascinating.\"]\n",
    "Word Tokenization: Splits sentences into individual words. Used for tasks like word frequency analysis and text classification.\n",
    "Example: \"I love NLP.\" → [\"I\", \"love\", \"NLP\", \".\"]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d07de66-ab6f-46b8-89f8-92aeaee18551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9)What are co-occurrence vectors in NLP?\\nCo-occurrence vectors are representations of words based on their co-occurrence with other words in a corpus. They are used in distributional semantics, which assumes that words appearing in similar contexts have similar meanings.\\nExample: A co-occurrence matrix for \"dog\" might count how often \"dog\" appears near words like \"bark\", \"puppy\", or \"pet\".'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''9)What are co-occurrence vectors in NLP?\n",
    "Co-occurrence vectors are representations of words based on their co-occurrence with other words in a corpus. They are used in distributional semantics, which assumes that words appearing in similar contexts have similar meanings.\n",
    "Example: A co-occurrence matrix for \"dog\" might count how often \"dog\" appears near words like \"bark\", \"puppy\", or \"pet\".'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a758729-86ea-46ce-96d8-ce7983debc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10)What is the significance of lemmatization in improving NLP tasks?\\nLemmatization improves NLP tasks by:\\n\\nReducing inflected forms of words to their base form, ensuring consistency.\\nImproving model accuracy by reducing the dimensionality of the vocabulary.\\nEnabling better context-based understanding in tasks like machine translation, information retrieval, and sentiment analysis.\\nExample: Without lemmatization, \"runs\", \"running\", and \"ran\" would be treated as separate words, increasing complexity.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''10)What is the significance of lemmatization in improving NLP tasks?\n",
    "Lemmatization improves NLP tasks by:\n",
    "\n",
    "Reducing inflected forms of words to their base form, ensuring consistency.\n",
    "Improving model accuracy by reducing the dimensionality of the vocabulary.\n",
    "Enabling better context-based understanding in tasks like machine translation, information retrieval, and sentiment analysis.\n",
    "Example: Without lemmatization, \"runs\", \"running\", and \"ran\" would be treated as separate words, increasing complexity.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881244da-8a32-4455-bc83-be19644fa085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11. What is the primary use of word embeddings in NLP?\\nWord embeddings are used to represent words in a continuous vector space, capturing their semantic and syntactic relationships. These dense, low-dimensional vectors help:\\n\\nIdentify word similarities (e.g., \"king\" and \"queen\").\\nImprove performance in NLP tasks like sentiment analysis, machine translation, and question-answering.\\nThey allow models to leverage contextual meaning instead of treating words as isolated tokens.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''11. What is the primary use of word embeddings in NLP?\n",
    "Word embeddings are used to represent words in a continuous vector space, capturing their semantic and syntactic relationships. These dense, low-dimensional vectors help:\n",
    "\n",
    "Identify word similarities (e.g., \"king\" and \"queen\").\n",
    "Improve performance in NLP tasks like sentiment analysis, machine translation, and question-answering.\n",
    "They allow models to leverage contextual meaning instead of treating words as isolated tokens.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55f3d15-2a5f-4509-a7d4-09dc52797499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12. What is an annotator in NLP?\\nAn annotator in NLP is a tool or process that labels text with metadata or tags to enhance understanding. For example:\\n\\nPart-of-speech (POS) tagging annotates each word with its grammatical role (e.g., noun, verb).\\nNamed Entity Recognition (NER) annotates entities like names, locations, or dates.\\nAnnotations are crucial for supervised learning and corpus analysis.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''12. What is an annotator in NLP?\n",
    "An annotator in NLP is a tool or process that labels text with metadata or tags to enhance understanding. For example:\n",
    "\n",
    "Part-of-speech (POS) tagging annotates each word with its grammatical role (e.g., noun, verb).\n",
    "Named Entity Recognition (NER) annotates entities like names, locations, or dates.\n",
    "Annotations are crucial for supervised learning and corpus analysis.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec610c7-f5a2-4584-a080-9f1ad7e025fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13. What are the key steps in text processing before applying machine learning models?\\nKey steps in text preprocessing include:\\n\\nText Cleaning: Removing noise (e.g., punctuation, HTML tags, or special characters).\\nTokenization: Breaking text into words or sentences.\\nLowercasing: Standardizing case to reduce dimensionality.\\nStopword Removal: Removing common but non-informative words (e.g., \"the\", \"is\").\\nStemming/Lemmatization: Reducing words to their base forms.\\nVectorization: Converting text into numerical formats (e.g., TF-IDF, word embeddings).\\nThese steps ensure consistency, reduce noise, and enhance model performance.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''13. What are the key steps in text processing before applying machine learning models?\n",
    "Key steps in text preprocessing include:\n",
    "\n",
    "Text Cleaning: Removing noise (e.g., punctuation, HTML tags, or special characters).\n",
    "Tokenization: Breaking text into words or sentences.\n",
    "Lowercasing: Standardizing case to reduce dimensionality.\n",
    "Stopword Removal: Removing common but non-informative words (e.g., \"the\", \"is\").\n",
    "Stemming/Lemmatization: Reducing words to their base forms.\n",
    "Vectorization: Converting text into numerical formats (e.g., TF-IDF, word embeddings).\n",
    "These steps ensure consistency, reduce noise, and enhance model performance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c96e35ae-f9f9-4ecb-b040-98b0f5ab2e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14. What is the history of NLP and how has it evolved?\\nNLP has evolved in the following stages:\\n\\n1950s–1970s: Rule-based systems and symbolic NLP, inspired by linguistics. Early systems like ELIZA relied on pattern matching.\\n1980s–1990s: Statistical NLP emerged with the availability of corpora and probabilistic models like Hidden Markov Models (HMMs).\\n2000s: Machine learning became dominant, with techniques like SVMs and logistic regression applied to NLP tasks.\\n2010s–Present: Deep learning revolutionized NLP with neural networks, leading to word embeddings (e.g., Word2Vec) and transformers (e.g., BERT, GPT). Current systems achieve state-of-the-art results in tasks like machine translation and conversational AI.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''14. What is the history of NLP and how has it evolved?\n",
    "NLP has evolved in the following stages:\n",
    "\n",
    "1950s–1970s: Rule-based systems and symbolic NLP, inspired by linguistics. Early systems like ELIZA relied on pattern matching.\n",
    "1980s–1990s: Statistical NLP emerged with the availability of corpora and probabilistic models like Hidden Markov Models (HMMs).\n",
    "2000s: Machine learning became dominant, with techniques like SVMs and logistic regression applied to NLP tasks.\n",
    "2010s–Present: Deep learning revolutionized NLP with neural networks, leading to word embeddings (e.g., Word2Vec) and transformers (e.g., BERT, GPT). Current systems achieve state-of-the-art results in tasks like machine translation and conversational AI.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33bd9d07-7eac-4239-96b6-305238a90527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15. Why is sentence processing important in NLP?\\nSentence processing ensures that the meaning and structure of a sentence are correctly analyzed. It is important for tasks like:\\n\\nSentiment analysis (e.g., identifying the sentiment of each sentence).\\nSummarization (e.g., generating concise summaries).\\nMachine translation (e.g., preserving context and grammar).\\nSentence-level context provides a richer understanding compared to isolated words.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''15. Why is sentence processing important in NLP?\n",
    "Sentence processing ensures that the meaning and structure of a sentence are correctly analyzed. It is important for tasks like:\n",
    "\n",
    "Sentiment analysis (e.g., identifying the sentiment of each sentence).\n",
    "Summarization (e.g., generating concise summaries).\n",
    "Machine translation (e.g., preserving context and grammar).\n",
    "Sentence-level context provides a richer understanding compared to isolated words.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f040692e-3b87-4af9-a327-a3935b0e6e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16. How do word embeddings improve the understanding of language semantics in NLP?\\nWord embeddings capture semantic relationships by placing similar words close to each other in a vector space. This improves understanding by:\\n\\nEncoding context and similarity (e.g., \"king\" and \"queen\").\\nSupporting analogies (e.g., \"Paris - France + Italy ≈ Rome\").\\nHandling polysemy by learning context-dependent representations (e.g., different meanings of \"bank\").\\nOverall, embeddings provide a foundation for language understanding in modern NLP.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''16. How do word embeddings improve the understanding of language semantics in NLP?\n",
    "Word embeddings capture semantic relationships by placing similar words close to each other in a vector space. This improves understanding by:\n",
    "\n",
    "Encoding context and similarity (e.g., \"king\" and \"queen\").\n",
    "Supporting analogies (e.g., \"Paris - France + Italy ≈ Rome\").\n",
    "Handling polysemy by learning context-dependent representations (e.g., different meanings of \"bank\").\n",
    "Overall, embeddings provide a foundation for language understanding in modern NLP.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a0b568-562a-4034-b368-38d469ba20df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17. How does the frequency distribution of words help in text classification?\\nFrequency distribution identifies common and rare terms, which helps:\\n\\nFeature selection: Removing low-information words (e.g., stopwords).\\nIdentifying domain-specific keywords (e.g., \"virus\" in medical texts).\\nCreating input features for models (e.g., Bag-of-Words or TF-IDF).\\nIt ensures that the most relevant terms contribute to classification.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''17. How does the frequency distribution of words help in text classification?\n",
    "Frequency distribution identifies common and rare terms, which helps:\n",
    "\n",
    "Feature selection: Removing low-information words (e.g., stopwords).\n",
    "Identifying domain-specific keywords (e.g., \"virus\" in medical texts).\n",
    "Creating input features for models (e.g., Bag-of-Words or TF-IDF).\n",
    "It ensures that the most relevant terms contribute to classification.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e8c42cb-ae9b-41a9-9f21-921b00c991f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6052\\184785604.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  '''18. What are the advantages of using regex in text cleaning?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'18. What are the advantages of using regex in text cleaning?\\nRegex (Regular Expressions) is highly flexible and efficient for text cleaning. Advantages include:\\n\\nPattern Matching: Identifying text formats like emails, dates, or phone numbers.\\nText Replacement: Removing or replacing unwanted characters.\\nCustom Filters: Building tailored rules for specific text-processing needs.\\nExample: Removing numbers from text: \\\\d+.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''18. What are the advantages of using regex in text cleaning?\n",
    "Regex (Regular Expressions) is highly flexible and efficient for text cleaning. Advantages include:\n",
    "\n",
    "Pattern Matching: Identifying text formats like emails, dates, or phone numbers.\n",
    "Text Replacement: Removing or replacing unwanted characters.\n",
    "Custom Filters: Building tailored rules for specific text-processing needs.\n",
    "Example: Removing numbers from text: \\d+.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a074bc4-d360-4df8-8a58-77b91a016932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19. What is the difference between Word2Vec and Doc2Vec?\\n\\nWord2Vec: Represents individual words as vectors, focusing on word-level semantic similarity.\\nDoc2Vec: Extends Word2Vec to represent entire documents or sentences as vectors, capturing document-level context.\\nDoc2Vec is useful for tasks like document classification and clustering, while Word2Vec is used for word-level tasks.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''19. What is the difference between Word2Vec and Doc2Vec?\n",
    "\n",
    "Word2Vec: Represents individual words as vectors, focusing on word-level semantic similarity.\n",
    "Doc2Vec: Extends Word2Vec to represent entire documents or sentences as vectors, capturing document-level context.\n",
    "Doc2Vec is useful for tasks like document classification and clustering, while Word2Vec is used for word-level tasks.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e499b55a-9520-4789-b790-40d0bf5c0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20. Why is understanding text normalization important in NLP?\\nText normalization ensures consistency and reduces noise, which is critical for NLP tasks. Benefits include:\\n\\nImproving model accuracy by standardizing inputs (e.g., \"USA\" and \"us\" → \"usa\").\\nReducing vocabulary size (e.g., converting \"running\" and \"ran\" to \"run\").\\nEnhancing feature engineering for machine learning.\\nWithout normalization, models may struggle with inconsistencies and miss relationships between similar text elements.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''20. Why is understanding text normalization important in NLP?\n",
    "Text normalization ensures consistency and reduces noise, which is critical for NLP tasks. Benefits include:\n",
    "\n",
    "Improving model accuracy by standardizing inputs (e.g., \"USA\" and \"us\" → \"usa\").\n",
    "Reducing vocabulary size (e.g., converting \"running\" and \"ran\" to \"run\").\n",
    "Enhancing feature engineering for machine learning.\n",
    "Without normalization, models may struggle with inconsistencies and miss relationships between similar text elements.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7a8a398-cec5-4554-a73f-c1e009995347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21. How does word count help in text analysis?\\nWord count provides insights into the importance or relevance of specific terms within a text. It helps:\\n\\nIdentify frequently used terms to understand the main topics or themes.\\nSpot stopwords or domain-specific terms.\\nMeasure text length for readability analysis.\\nFor example, analyzing word frequency can reveal the key focus of a document'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''21. How does word count help in text analysis?\n",
    "Word count provides insights into the importance or relevance of specific terms within a text. It helps:\n",
    "\n",
    "Identify frequently used terms to understand the main topics or themes.\n",
    "Spot stopwords or domain-specific terms.\n",
    "Measure text length for readability analysis.\n",
    "For example, analyzing word frequency can reveal the key focus of a document'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fb23ba7-01b5-436a-bcbb-8feaa901b19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22. How does lemmatization help in NLP tasks like search engines and chatbots?\\nLemmatization reduces words to their base form (lemma), improving consistency. In search engines and chatbots, it:\\n\\nEnhances search accuracy by matching queries with indexed content more effectively.\\n(e.g., \"running\", \"ran\" → \"run\").\\nImproves response relevance by understanding user intent regardless of word variations.\\nReduces vocabulary size for faster processing and storage.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''22. How does lemmatization help in NLP tasks like search engines and chatbots?\n",
    "Lemmatization reduces words to their base form (lemma), improving consistency. In search engines and chatbots, it:\n",
    "\n",
    "Enhances search accuracy by matching queries with indexed content more effectively.\n",
    "(e.g., \"running\", \"ran\" → \"run\").\n",
    "Improves response relevance by understanding user intent regardless of word variations.\n",
    "Reduces vocabulary size for faster processing and storage.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78285856-3d15-45d8-9fca-3909647e60f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23. What is the purpose of using Doc2Vec in text processing?\\nDoc2Vec generates vector representations for entire documents, capturing their semantic meaning. It is useful for:\\n\\nDocument classification or clustering.\\nInformation retrieval (e.g., finding similar documents).\\nText summarization and recommendation systems.\\nDoc2Vec considers both word context and document-level context.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''23. What is the purpose of using Doc2Vec in text processing?\n",
    "Doc2Vec generates vector representations for entire documents, capturing their semantic meaning. It is useful for:\n",
    "\n",
    "Document classification or clustering.\n",
    "Information retrieval (e.g., finding similar documents).\n",
    "Text summarization and recommendation systems.\n",
    "Doc2Vec considers both word context and document-level context.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "973d1255-5a6c-4938-9a70-3c7143f1ea4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24. What is the importance of sentence processing in NLP?\\nSentence processing is critical because sentences convey complete thoughts. It:\\n\\nPreserves grammatical structures and context.\\nImproves understanding for tasks like translation, summarization, and question-answering.\\nEnsures that models consider sentence boundaries to avoid misinterpretation of meaning.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''24. What is the importance of sentence processing in NLP?\n",
    "Sentence processing is critical because sentences convey complete thoughts. It:\n",
    "\n",
    "Preserves grammatical structures and context.\n",
    "Improves understanding for tasks like translation, summarization, and question-answering.\n",
    "Ensures that models consider sentence boundaries to avoid misinterpretation of meaning.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5ee4704-6f85-4967-80fb-c09b2f0bb9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25. What is text normalization, and what are the common techniques used in it?\\nText normalization standardizes text into a consistent format for analysis. Common techniques include:\\n\\nLowercasing: Converts all text to lowercase.\\nRemoving punctuation: Eliminates unnecessary characters.\\nExpanding contractions: Converts \"don\\'t\" → \"do not\".\\nStemming/Lemmatization: Reduces words to their base form.\\nRemoving stopwords: Removes words like \"the\", \"is\", etc.\\nNormalization reduces noise and improves model performance.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''25. What is text normalization, and what are the common techniques used in it?\n",
    "Text normalization standardizes text into a consistent format for analysis. Common techniques include:\n",
    "\n",
    "Lowercasing: Converts all text to lowercase.\n",
    "Removing punctuation: Eliminates unnecessary characters.\n",
    "Expanding contractions: Converts \"don't\" → \"do not\".\n",
    "Stemming/Lemmatization: Reduces words to their base form.\n",
    "Removing stopwords: Removes words like \"the\", \"is\", etc.\n",
    "Normalization reduces noise and improves model performance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe05a4ec-3a8b-4148-92b6-274f0ab11d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26. Why is word tokenization important in NLP?\\nWord tokenization breaks text into individual words, which are fundamental units for analysis. It is important for:\\n\\nCreating input features for machine learning models.\\nEnabling tasks like POS tagging, word embeddings, and frequency analysis.\\nPreparing data for downstream tasks like sentiment analysis and language translation.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''26. Why is word tokenization important in NLP?\n",
    "Word tokenization breaks text into individual words, which are fundamental units for analysis. It is important for:\n",
    "\n",
    "Creating input features for machine learning models.\n",
    "Enabling tasks like POS tagging, word embeddings, and frequency analysis.\n",
    "Preparing data for downstream tasks like sentiment analysis and language translation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25e342a2-cb72-4eec-b82e-23d7d2f01d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27. How does sentence tokenization differ from word tokenization in NLP?\\n\\nSentence Tokenization: Splits text into sentences. Useful for tasks like summarization and sentiment analysis at the sentence level.\\nExample: \"NLP is fun. It is exciting.\" → [\"NLP is fun.\", \"It is exciting.\"]\\nWord Tokenization: Splits sentences into words. Used for tasks like word frequency analysis and POS tagging.\\nExample: \"NLP is fun.\" → [\"NLP\", \"is\", \"fun\"].'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''27. How does sentence tokenization differ from word tokenization in NLP?\n",
    "\n",
    "Sentence Tokenization: Splits text into sentences. Useful for tasks like summarization and sentiment analysis at the sentence level.\n",
    "Example: \"NLP is fun. It is exciting.\" → [\"NLP is fun.\", \"It is exciting.\"]\n",
    "Word Tokenization: Splits sentences into words. Used for tasks like word frequency analysis and POS tagging.\n",
    "Example: \"NLP is fun.\" → [\"NLP\", \"is\", \"fun\"].'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4b8fb4d-570b-40fb-a0e1-cb500916b91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28. What is the primary purpose of text processing in NLP?\\nThe primary purpose of text processing is to clean and prepare raw text data for analysis or modeling. It reduces noise, standardizes input, and extracts meaningful features, enabling efficient and accurate text-based predictions or insights.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''28. What is the primary purpose of text processing in NLP?\n",
    "The primary purpose of text processing is to clean and prepare raw text data for analysis or modeling. It reduces noise, standardizes input, and extracts meaningful features, enabling efficient and accurate text-based predictions or insights.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d7fa3f6-f197-4765-9731-d021beff2432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29. What are the key challenges in NLP?\\nKey challenges in NLP include:\\n\\nAmbiguity: Words and sentences can have multiple meanings (e.g., polysemy).\\nContext Understanding: Capturing long-range dependencies and context.\\nSarcasm/Irony Detection: Understanding nuanced language.\\nLow-Resource Languages: Lack of annotated data for some languages.\\nScalability: Processing large-scale text efficiently.\\nEthical Issues: Avoiding biases in data and models.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''29. What are the key challenges in NLP?\n",
    "Key challenges in NLP include:\n",
    "\n",
    "Ambiguity: Words and sentences can have multiple meanings (e.g., polysemy).\n",
    "Context Understanding: Capturing long-range dependencies and context.\n",
    "Sarcasm/Irony Detection: Understanding nuanced language.\n",
    "Low-Resource Languages: Lack of annotated data for some languages.\n",
    "Scalability: Processing large-scale text efficiently.\n",
    "Ethical Issues: Avoiding biases in data and models.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec23e641-884e-4507-95e4-0dd997fbfbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30. How do co-occurrence vectors represent relationships between words?\\nCo-occurrence vectors are constructed by counting how often words appear near each other in a corpus. They represent semantic relationships by encoding contextual similarity.\\nFor example: If \"doctor\" frequently co-occurs with \"hospital\" and \"patient\", the vector for \"doctor\" will reflect this relationship, indicating relevance.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''30. How do co-occurrence vectors represent relationships between words?\n",
    "Co-occurrence vectors are constructed by counting how often words appear near each other in a corpus. They represent semantic relationships by encoding contextual similarity.\n",
    "For example: If \"doctor\" frequently co-occurs with \"hospital\" and \"patient\", the vector for \"doctor\" will reflect this relationship, indicating relevance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2029c209-4b96-4542-a580-dce602a4a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'31. What is the role of frequency distribution in text analysis?\\nFrequency distribution identifies the occurrence of each word in a corpus. Its role includes:\\n\\nHighlighting key terms or topics in the text.\\nGuiding feature selection by focusing on frequent or rare words.\\nAssisting in building word-based models like Bag-of-Words and TF-IDF.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''31. What is the role of frequency distribution in text analysis?\n",
    "Frequency distribution identifies the occurrence of each word in a corpus. Its role includes:\n",
    "\n",
    "Highlighting key terms or topics in the text.\n",
    "Guiding feature selection by focusing on frequent or rare words.\n",
    "Assisting in building word-based models like Bag-of-Words and TF-IDF.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d237a0f-872d-42dd-b7c4-00c8de889882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32. What is the impact of word embeddings on NLP tasks?\\nWord embeddings revolutionized NLP by providing dense, semantic representations of words, enabling:\\n\\nBetter understanding of word relationships and analogies.\\nImproved accuracy in tasks like sentiment analysis, machine translation, and question-answering.\\nEfficient use of computational resources due to lower-dimensional representations.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''32. What is the impact of word embeddings on NLP tasks?\n",
    "Word embeddings revolutionized NLP by providing dense, semantic representations of words, enabling:\n",
    "\n",
    "Better understanding of word relationships and analogies.\n",
    "Improved accuracy in tasks like sentiment analysis, machine translation, and question-answering.\n",
    "Efficient use of computational resources due to lower-dimensional representations.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "807863c9-3246-4211-878f-6ce8fdfba328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33. What is the purpose of using lemmatization in text preprocessing?\\nThe purpose of lemmatization is to reduce words to their canonical form (lemma), improving consistency. This helps:\\n\\nMinimize vocabulary size by grouping similar words (e.g., \"running\", \"ran\" → \"run\").\\nEnhance the performance of search engines, chatbots, and classifiers by focusing on core meanings.\\nLemmatization ensures that variations of a word are treated as a single entity.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''33. What is the purpose of using lemmatization in text preprocessing?\n",
    "The purpose of lemmatization is to reduce words to their canonical form (lemma), improving consistency. This helps:\n",
    "\n",
    "Minimize vocabulary size by grouping similar words (e.g., \"running\", \"ran\" → \"run\").\n",
    "Enhance the performance of search engines, chatbots, and classifiers by focusing on core meanings.\n",
    "Lemmatization ensures that variations of a word are treated as a single entity.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb36aa-b26a-4146-8742-8abe69f9511a",
   "metadata": {},
   "source": [
    "# practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87fdf90f-237e-4988-bf1a-fd2cb892d3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'is', 'fun', '!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#1).How can you perform word tokenization using NLTK?\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "text = \"Natural Language Processing is fun!\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e85163c9-7aaa-4c48-8928-3a3e2a8cc684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural Language Processing is fun.', 'It helps machines understand human language.']\n"
     ]
    }
   ],
   "source": [
    "#2)How can you perform sentence tokenization using NLTK\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"Natural Language Processing is fun. It helps machines understand human language.\"\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97a7d88b-c1d1-4338-aeb1-b2a8c28e9e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example', 'sentence', 'demonstrating', 'stopword', 'removal', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#3)How can you remove stopwords from a sentence?\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "text = \"This is an example sentence demonstrating stopword removal.\"\n",
    "tokens = word_tokenize(text)\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4afecb33-23c7-4970-a9ed-7706ef1a726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "#4)How can you perform stemming on a word?\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "word = \"running\"\n",
    "stemmed_word = stemmer.stem(word)\n",
    "print(stemmed_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5704fafd-caa9-4334-ac2c-c08edc5f0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#5)How can you perform lemmatization on a word?\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word = \"running\"\n",
    "lemma = lemmatizer.lemmatize(word, pos='v')  # 'v' for verb\n",
    "print(lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5df7725f-3b4f-4566-9e0c-47ff7aab37b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello nlp is exciting\n"
     ]
    }
   ],
   "source": [
    "#6)How can you normalize a text by converting it to lowercase and removing punctuation?\n",
    "import string\n",
    "\n",
    "text = \"Hello, NLP is exciting!\"\n",
    "normalized_text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "print(normalized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49f46e5e-9483-4348-9964-4575088600b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('I', 'love'): 1, ('love', 'NLP'): 1, ('NLP', 'is'): 1, ('is', 'fun'): 1, ('I', 'enjoy'): 1, ('enjoy', 'learning'): 1, ('learning', 'NLP'): 1})\n"
     ]
    }
   ],
   "source": [
    "#7)How can you create a co-occurrence matrix for words in a corpus?\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "corpus = [\"I love NLP\", \"NLP is fun\", \"I enjoy learning NLP\"]\n",
    "window_size = 2\n",
    "co_occurrence = Counter()\n",
    "\n",
    "for sentence in corpus:\n",
    "    tokens = sentence.split()\n",
    "    for i in range(len(tokens) - window_size + 1):\n",
    "        window = tokens[i:i + window_size]\n",
    "        for pair in combinations(window, 2):\n",
    "            co_occurrence[pair] += 1\n",
    "\n",
    "print(co_occurrence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e981b19-e528-4494-9fd8-f6d8049f200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support@example.com', 'sales@example.org']\n"
     ]
    }
   ],
   "source": [
    "#8)How can you apply a regular expression to extract all email addresses from a text?\n",
    "import re\n",
    "\n",
    "text = \"Contact us at support@example.com or sales@example.org.\"\n",
    "emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', text)\n",
    "print(emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "598f4904-1943-43fc-86b9-a4f510a43a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
      "Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/24.0 MB 6.3 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.6/24.0 MB 3.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.1/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.9/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.7/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.5/24.0 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.3/24.0 MB 3.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.1/24.0 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.1/24.0 MB 3.7 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.9/24.0 MB 3.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 9.7/24.0 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.5/24.0 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.3/24.0 MB 3.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.1/24.0 MB 3.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.1/24.0 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.6/24.0 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.7/24.0 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.5/24.0 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.3/24.0 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.9/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.7/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.4/24.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.2/24.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.8/15.5 MB 4.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.6/15.5 MB 4.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.4/15.5 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.2/15.5 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.2/15.5 MB 4.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 6.0/15.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.8/15.5 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.6/15.5 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.4/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.2/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.0/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.7/15.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.8/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.6/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "   ---------------------------------------- 0.0/45.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/45.9 MB 5.6 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.8/45.9 MB 4.6 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.6/45.9 MB 4.3 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 3.4/45.9 MB 4.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 4.2/45.9 MB 4.1 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 5.0/45.9 MB 4.0 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 6.0/45.9 MB 4.0 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 6.8/45.9 MB 4.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 7.6/45.9 MB 4.0 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 8.4/45.9 MB 3.9 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 9.2/45.9 MB 3.9 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 10.0/45.9 MB 3.9 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 10.7/45.9 MB 3.9 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 11.5/45.9 MB 3.9 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 12.6/45.9 MB 3.9 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 13.4/45.9 MB 3.9 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 14.2/45.9 MB 3.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 14.9/45.9 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 15.7/45.9 MB 3.9 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 16.5/45.9 MB 3.9 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 17.3/45.9 MB 3.9 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 18.1/45.9 MB 3.9 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 18.9/45.9 MB 3.9 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 19.9/45.9 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 20.7/45.9 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 21.5/45.9 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 22.3/45.9 MB 3.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 23.1/45.9 MB 3.9 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 23.9/45.9 MB 3.9 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 24.9/45.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 25.7/45.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 26.5/45.9 MB 3.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 27.3/45.9 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 28.0/45.9 MB 3.9 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 28.8/45.9 MB 3.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 29.9/45.9 MB 3.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 30.4/45.9 MB 3.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 31.5/45.9 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 32.2/45.9 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 33.0/45.9 MB 3.9 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 33.8/45.9 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 34.6/45.9 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 35.4/45.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 36.2/45.9 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 37.2/45.9 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 38.0/45.9 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 38.8/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 39.6/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 40.4/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 41.2/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.9/45.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.7/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.8/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.6/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.4/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.9/45.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.9/45.9 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.0\n",
      "    Uninstalling scipy-1.14.0:\n",
      "      Successfully uninstalled scipy-1.14.0\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~~mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.28.0 requires protobuf<5,>=3.20, but you have protobuf 5.27.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14d0084c-d7b2-4845-89f1-bb9aee40fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==4.3.0\n",
      "  Downloading gensim-4.3.0.tar.gz (23.3 MB)\n",
      "     ---------------------------------------- 0.0/23.3 MB ? eta -:--:--\n",
      "     - -------------------------------------- 1.0/23.3 MB 7.2 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.8/23.3 MB 5.0 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 2.6/23.3 MB 4.6 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 3.4/23.3 MB 4.4 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 4.2/23.3 MB 4.3 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 5.2/23.3 MB 4.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 6.0/23.3 MB 4.1 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 6.8/23.3 MB 4.1 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 7.6/23.3 MB 4.1 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 8.7/23.3 MB 4.1 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 9.4/23.3 MB 4.1 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 10.2/23.3 MB 4.0 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 11.0/23.3 MB 4.0 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 11.8/23.3 MB 4.0 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 12.8/23.3 MB 4.0 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 13.6/23.3 MB 4.0 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 14.4/23.3 MB 4.0 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 15.2/23.3 MB 4.0 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 16.0/23.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.8/23.3 MB 3.9 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 17.8/23.3 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 18.6/23.3 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 19.4/23.3 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.2/23.3 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.0/23.3 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.0/23.3 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/23.3 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.3/23.3 MB 3.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5.tar.gz (10.7 MB)\n",
      "     ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/10.7 MB 5.6 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.8/10.7 MB 4.6 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 2.9/10.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 3.7/10.7 MB 4.2 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 4.5/10.7 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.2/10.7 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 6.0/10.7 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 6.8/10.7 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 7.6/10.7 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.7/10.7 MB 4.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.4/10.7 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 10.2/10.7 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.7/10.7 MB 3.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [33 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "      backend = _build_backend()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "      obj = import_module(mod_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "    File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-u8398rtu\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n",
      "      import setuptools.version\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-u8398rtu\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n",
      "      import pkg_resources\n",
      "    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-u8398rtu\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n",
      "      register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim==4.3.0 numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85d06578-0bf6-437a-9491-093d883c8a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Using cached Cython-3.0.11-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Using cached Cython-3.0.11-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "Installing collected packages: cython\n",
      "Successfully installed cython-3.0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Using cached gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.17.0\n",
      "    Uninstalling wrapt-1.17.0:\n",
      "      Successfully uninstalled wrapt-1.17.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 7.1.0\n",
      "    Uninstalling smart-open-7.1.0:\n",
      "      Successfully uninstalled smart-open-7.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.3\n",
      "    Uninstalling gensim-4.3.3:\n",
      "      Successfully uninstalled gensim-4.3.3\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~rapt'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~ensim'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.28.0 requires protobuf<5,>=3.20, but you have protobuf 5.27.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install cython\n",
    "!pip install --force-reinstall gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3093788b-e0f0-4349-be2f-e5b52261aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f79bd2b0-dfbb-42aa-9831-35c505e9f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26055567]]\n"
     ]
    }
   ],
   "source": [
    "#12)How can you find the similarity between two sentences using cosine similarity?\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sentences = [\"I love NLP\", \"NLP is amazing\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(sentences)\n",
    "similarity = cosine_similarity(vectors[0], vectors[1])\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fb92f59-89f1-465e-a267-8342e06334b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This is a large document.', 'It has multiple sentences.'], [\"Let's split it.\"]]\n"
     ]
    }
   ],
   "source": [
    "#14)How can you split a large document into smaller chunks of text?\n",
    "text = \"This is a large document. It has multiple sentences. Let's split it.\"\n",
    "chunk_size = 2\n",
    "sentences = sent_tokenize(text)\n",
    "chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "print(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed084de8-3abe-43e3-b0f1-d9b69fef4941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.861037   0.50854232]\n",
      " [0.         0.65249088 0.65249088 0.         0.         0.38537163]\n",
      " [0.65249088 0.         0.         0.65249088 0.         0.38537163]]\n"
     ]
    }
   ],
   "source": [
    "#15)How can you calculate the TF-IDF (Term Frequency - Inverse Document Frequency) for a set of documents?\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\"I love NLP\", \"NLP is fun\", \"I enjoy learning NLP\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "print(tfidf_matrix.toarray())  # TF-IDF values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00d4ad63-f3a0-457b-b035-15ca0ea434a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simpl', 'nlp', 'exampl', 'show', 'combin', 'preprocess', 'step', '.']\n"
     ]
    }
   ],
   "source": [
    "#16)How can you apply tokenization, stopword removal, and stemming in one go?\n",
    "text = \"This is a simple NLP example showing how to combine preprocessing steps.\"\n",
    "tokens = word_tokenize(text)\n",
    "filtered_tokens = [stemmer.stem(word) for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea8c3994-f345-44b4-bf6b-0d1132d73da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Word Frequency Distribution'}, xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#17)How can you visualize the frequency distribution of words in a sentence?\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "text = \"NLP is fun. NLP is powerful. NLP is the future!\"\n",
    "tokens = word_tokenize(text)\n",
    "freq_dist = FreqDist(tokens)\n",
    "freq_dist.plot(10, title=\"Word Frequency Distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b42fb8-d44e-4ff3-a5a9-5498e8c4a699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
